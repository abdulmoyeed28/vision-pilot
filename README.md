
# ğŸ¯ VisionPilot: Gesture-Controlled Interaction Suite

VisionPilot is a real-time webcam-based control system that lets you interact with applications and browser-based games using hand gestures â€” no keyboard or mouse required.

ğŸ–ï¸ Move your cursor, ğŸ® shoot in games, or ğŸï¸ steer cars, all using natural hand movements.

---

## ğŸš€ Features

- ğŸ¯ **Finger-Based Mouse & Click Control**
- ğŸï¸ **Steering Control for Driving Games**
- ğŸ® **Game-Ready with Real-Time Speed**
- ğŸ“· Built using **OpenCV**, **MediaPipe**, and **Streamlit**
- âœ… Works on most standard webcams and modern browsers

---

## ğŸ“ Project Structure

```plaintext
VisionPilot/
â”œâ”€â”€ main.py                  # Entry point (Streamlit app)
â”œâ”€â”€ shooter.py              # Cursor control + shooting mode
â”œâ”€â”€ steering.py             # Steering wheel hand-tracking
â”œâ”€â”€ keyinput.py             # Virtual key presses
â”œâ”€â”€ util.py                 # Helpers for gesture logic
â”œâ”€â”€ config.toml             # UI + detection config
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ about.py                # About section (Streamlit)
â”œâ”€â”€ developers.py           # Developer info section
```

---

## ğŸ› ï¸ Getting Started

## 1. Clone the Repository

```bash
git clone https://github.com/abdulmoyeed28/vision-pilot.git
cd vision-pilot
```

## 2. Install Dependencies

```bash
pip install -r requirements.txt
```

## 3. Run the App

```bash
streamlit run main.py
```

## ğŸ“¦ Tech Stack

ğŸ§  Python 3  
ğŸ–¼ï¸ OpenCV  
ğŸ§â€â™‚ï¸ MediaPipe  
ğŸŒ Streamlit  
ğŸ’» PyAutoGUI  

## ğŸ§  How It Works

VisionPilot uses MediaPipeâ€™s real-time hand tracking to:  

Detect fingertips and hand poses  
Control the mouse via single-finger gestures  
Simulate clicks (for games like shooters)  
Track two-hand distances (for steering-like motion)  
Gestures are translated into input commands using PyAutoGUI to control applications and games seamlessly.  

---

ğŸ† **Awards & Recognition**

ğŸ¥ˆ **2nd Prize** â€“ Project Expo 2025  
Lords Institute of Engineering & Technology  
Awarded for *VisionPilot* among 60+ competing teams.

---

ğŸ™Œ **Acknowledgements**

Thanks to the open-source tools that made this possible:

- [Google MediaPipe](https://github.com/google/mediapipe) â€“ real-time hand tracking  
- [OpenCV](https://opencv.org/) â€“ image processing  
- [PyAutoGUI](https://pyautogui.readthedocs.io/) â€“ simulating input events  
- [Streamlit](https://streamlit.io/) â€“ UI interface  

---
